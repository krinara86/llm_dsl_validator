# LLM to DSL translation

This project demonstrates a system that uses a custom DSL and interpreter to enforce business logic on the output of a Large Language Model (LLM).


## System Architecture

System comprises of two parts:

1.  **Translation:** An LLM (Ollama's Llama 3) takes a conversational, unstructured user query and translates it into a formal, structured representation using a DSL built on top of [Lark](https://github.com/lark-parser/lark) .
2.  **Interpretation:** A custom interpreter, written in Python using Lark's parsing library, executes the DSL code. 


---

## How to Run the Demo

### 1. Prerequisites: Install Ollama

This demo requires a local Ollama server.

1.  **Install Ollama:** Download from <https://ollama.com>.
2.  **Download the Model:** Open a terminal and run:
    ```bash
    ollama pull llama3:8b
    ```

### 2. Setup the Python Environment

The demo is a Jupyter Notebook.

1.  **Navigate to the Project Folder:**
    ```bash
    cd llm_dsl_validator
    ```
2.  **Create and Activate a Virtual Environment:**
    ```bash
    python -m venv venv
    .\venv\Scripts\Activate.ps1
    ```
    *(Note: On PowerShell, you may first need to run `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process`)*

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

### 3. Launch the Notebook

1.  **Start the Jupyter Server:**
    ```bash
    jupyter notebook
    ```
2.  **Run the Demo:** Open `notebooks/demo.ipynb` in your browser and execute the cells in order.

---

## Implementation Details

### Restaurant bill DSL 

Bills have the syntax `bill` followed `items` each of which have a name followed by the quantity of the item and the price or just the price if there is only one of the said item. 

**Grammar (`tax_rules.dsl`):**
```
start: bill
bill: "bill" "{" items "}"
items: item+
item: CNAME ":" NUMBER "*" NUMBER -> line_item_with_quantity
    | CNAME ":" NUMBER           -> line_item_simple

%import common.CNAME
%import common.NUMBER
%import common.WS
%ignore WS
```

**Example DSL Code (Generated by LLM):**
```
bill {
  burger: 2 * 10
  soda: 3
}
```

### Interpreter

The interpreter (`src/interpreter.py`) implements the Lark `Transformer`. 

* The `BillInterpreter` class contains methods that match the rule names in the grammar (e.g., `line_item_with_quantity`, `bill`).
* The `_classify_and_add` helper method is responsible for categorizing items into "food" or "drink" based on hardcoded keywords.
* The `bill` method is responsible for applying the fixed 7% and 19% tax rates and calculating the final total.

This interpreter acts as a "source of truth" for all calculations.

### The LLM Prompt

```python
# From src/core.py
prompt = f"""
You are a helpful assistant that translates natural language into a custom DSL.
The DSL format is:
bill {{
  itemName: quantity * pricePerItem
  anotherItemName: price
}}

Translate the following user order into this DSL. The item names should be simple, lowercase words like 'burger' or 'soda'.

User Order: "{user_query}"

DSL Response:
"""
```

---

## Next Steps

### 1. Deploy as a service

The current model requires each user to run a local Ollama server. As part of this task, we will host the core components on a central server. 
Note: Part of this would involve exposing the logic in src/core.py as an API endpoint using some web framework like Flask or FastAPI. 

### 2. Expand the DSL and Interpreter

The `tax_rules.dsl` grammar can be updated to include new concepts, such as discounts, tips, or different item categories.

### 3. Incorporate other example DSLs

Consider other examples DSLs from other domains (finance, cycling?)

### 3. Build a Dedicated Web Frontend

Build a frontend (React, Vue?). Jupyter Notebooks are easy to work with, but not for demos. 
