# LLM to DSL Validator

This project demonstrates a system that uses a custom-built Domain-Specific Language (DSL) and interpreter to enforce business logic on the output of a Large Language Model (LLM).

The architecture is designed to leverage an LLM for its natural language understanding capabilities while using a deterministic, custom-built interpreter for critical business rules.

## System Architecture

The core of this system is a two-stage process:

1.  **Translation:** An LLM (Ollama's Llama 3) takes a conversational, unstructured user query and translates it into a formal, structured representation using our custom-built DSL.
2.  **Interpretation:** A custom interpreter, written in Python using the Lark parsing library, executes the DSL code. This interpreter contains the hardcoded business logic, ensuring the final result is always compliant.

This separation of concerns allows the system to be both flexible in its input and reliable in its output.

---

## How to Run the Demo

### 1. Prerequisites: Install Ollama

This demo requires a local Ollama server.

1.  **Install Ollama:** Download from <https://ollama.com>.
2.  **Download the Model:** Open a terminal and run:
    ```bash
    ollama pull llama3:8b
    ```

### 2. Setup the Python Environment

The demo is a Jupyter Notebook.

1.  **Navigate to the Project Folder:**
    ```bash
    cd llm_dsl_validator
    ```
2.  **Create and Activate a Virtual Environment:**
    ```bash
    python -m venv venv
    .\venv\Scripts\Activate.ps1
    ```
    *(Note: On PowerShell, you may first need to run `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process`)*

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

### 3. Launch the Notebook

1.  **Start the Jupyter Server:**
    ```bash
    jupyter notebook
    ```
2.  **Run the Demo:** Open `notebooks/demo.ipynb` in your browser and execute the cells in order.

---

## Technical Implementation Details

### The Custom DSL

The system uses a simple, text-based DSL for representing a restaurant bill. The formal grammar is defined in `tax_rules.dsl` using the Lark syntax.

**Grammar (`tax_rules.dsl`):**
```
start: bill
bill: "bill" "{" items "}"
items: item+
item: CNAME ":" NUMBER "*" NUMBER -> line_item_with_quantity
    | CNAME ":" NUMBER           -> line_item_simple

%import common.CNAME
%import common.NUMBER
%import common.WS
%ignore WS
```

**Example DSL Code (Generated by LLM):**
```
bill {
  burger: 2 * 10
  soda: 3
}
```

### The Custom Interpreter

The interpreter (`src/interpreter.py`) is a Python class that implements the Lark `Transformer` interface. It walks the parse tree generated by Lark and executes the business logic.

* The `BillInterpreter` class contains methods that match the rule names in the grammar (e.g., `line_item_with_quantity`, `bill`).
* The `_classify_and_add` helper method is responsible for categorizing items into "food" or "drink" based on hardcoded keywords.
* The `bill` method is responsible for applying the fixed 7% and 19% tax rates and calculating the final total.

This interpreter is the "source of truth" for all calculations.

### The LLM Prompt

The notebook uses a carefully engineered prompt to instruct the LLM to act as a translator, converting a user's conversational order into our formal DSL.

```python
# From src/core.py
prompt = f"""
You are a helpful assistant that translates natural language into a custom DSL.
The DSL format is:
bill {{
  itemName: quantity * pricePerItem
  anotherItemName: price
}}

Translate the following user order into this DSL. The item names should be simple, lowercase words like 'burger' or 'soda'.

User Order: "{user_query}"

DSL Response:
"""
```