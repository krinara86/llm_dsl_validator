# LLM to DSL Validator

This project demonstrates a system that uses a custom-built Domain-Specific Language (DSL) and interpreter to enforce business logic on the output of a Large Language Model (LLM).

The architecture is designed to leverage the LLM for its natural language understanding capabilities while using a deterministic interpreter for critical, non-negotiable business rules.

## System Architecture

The core of this system is a two-stage process:

1.  **Translation:** An LLM (Ollama's Llama 3) takes a conversational, unstructured user query and translates it into a formal, structured representation using our custom-built DSL.
2.  **Interpretation:** A custom-built interpreter, written in Python using the Lark parsing library, executes the DSL code. This interpreter contains the hardcoded business logic, ensuring the final result is always compliant.

This separation of concerns allows the system to be both flexible in its input and reliable in its output.

---

## How to Run the Demo

### 1. Prerequisites: Install Ollama

This demo requires a local Ollama server.

1.  **Install Ollama:** Download from <https://ollama.com>.
2.  **Download the Model:** Open a terminal and run:
    ```bash
    ollama pull llama3:8b
    ```

### 2. Setup the Python Environment

The demo is a Jupyter Notebook.

1.  **Navigate to the Project Folder:**
    ```bash
    cd llm_dsl_validator
    ```
2.  **Create and Activate a Virtual Environment:**
    ```bash
    python -m venv venv
    .\venv\Scripts\Activate.ps1
    ```
    *(Note: On PowerShell, you may first need to run `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process`)*

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

### 3. Launch the Notebook

1.  **Start the Jupyter Server:**
    ```bash
    jupyter notebook
    ```
2.  **Run the Demo:** Open `demo.ipynb` in your browser and execute the cells in order.

---

## Technical Implementation Details

### The Custom DSL

The system uses a simple, text-based DSL for representing a restaurant bill. The formal grammar is defined in `tax_rules.dsl` using the Lark syntax.

**Grammar (`tax_rules.dsl`):**
```
start: bill
bill: "bill" "{" items "}"
items: item+
item: CNAME ":" NUMBER -> line_item

%import common.CNAME
%import common.NUMBER
%import common.WS
%ignore WS
```

**Example DSL Code (Generated by LLM):**
```
bill {
  schnitzel: 30.00
  beer: 5.00
}
```

### The Custom Interpreter

The interpreter (`src/interpreter.py`) is a Python class that implements the Lark `Transformer` interface. It walks the parse tree generated by Lark and executes the business logic.

* The `BillInterpreter` class contains methods that match the rule names in the grammar (e.g., `line_item`, `bill`).
* The `line_item` method is responsible for classifying items into "food" or "drink" categories based on hardcoded keywords.
* The `bill` method is responsible for applying the fixed 7% and 19% tax rates and calculating the final total.

This interpreter is the "source of truth" for all calculations.

### The LLM Prompt

The notebook uses a carefully engineered prompt to instruct the LLM to act as a translator, converting a user's conversational order into our formal DSL.

```python
# From the notebook
prompt = f"""
You are a helpful assistant that translates natural language into a custom DSL.
The DSL format is:
bill {{
  itemName: itemValue
  anotherItemName: anotherItemValue
}}

Translate the following user order into this DSL. The item names should be simple, lowercase words.

User Order: "{user_query}"

DSL Response:
"""
```

### Final Output

The demo's final output is a table that shows the final, correct bill as calculated by the custom interpreter based on the DSL code generated by the LLM. If the LLM fails to generate valid or syntactically correct DSL, the system catches and reports the error.
